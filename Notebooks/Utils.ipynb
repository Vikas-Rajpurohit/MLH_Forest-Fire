{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f74a29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0157c856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\vikas/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "C:\\Users\\vikas\\Desktop\\ForestFireTracking\\envfire\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "YOLOv5  2024-5-25 Python-3.10.4 torch-2.2.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7246518 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', '../models/yoloFire.pt')  # force_reload=True to update\n",
    "\n",
    "# Other Parameters\n",
    "pd = 0\n",
    "text = \"emergency\"\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.8\n",
    "font_thickness = 1\n",
    "text_color = (255, 255, 255)  # White color\n",
    "pixel_length_meters = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e0b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af8d5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo(im, yolo_frame, size=640):\n",
    "    g = (size / max(im.size))  \n",
    "    im = im.resize((int(x * g) for x in im.size), Image.LANCZOS)\n",
    "    results = model(im)\n",
    "    \n",
    "    result_image = Image.fromarray(results.ims[0])\n",
    "    result_frame = np.array(result_image)\n",
    "    \n",
    "#     results.render()  -> YOLO Inference\n",
    "\n",
    "    for box in results.xyxy[0]:\n",
    "        xmin, ymin, xmax, ymax, _, _ = box\n",
    "        cv2.rectangle(result_frame, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (255, 0, 0), 2)\n",
    "        cv2.rectangle(yolo_frame, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 0, 255), -1)\n",
    "        \n",
    "                \n",
    "    area = 0\n",
    "    gray = cv2.cvtColor(yolo_frame, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Iterate through each contour\n",
    "    for contour in contours:\n",
    "        # Calculate area of the contour\n",
    "        pixel_area = cv2.contourArea(contour)  # Area in pixels\n",
    "\n",
    "        area += pixel_area\n",
    "            # Draw contour on the original image\n",
    "#             cv2.drawContours(black_frame, [contour], -1, (0, 255, 0), 1)\n",
    "        \n",
    "#         pr = area*100/(black_frame.shape[0]*black_frame.shape[1])\n",
    "        \n",
    "#         cv2.putText(black_frame, \"Area: {}%\".format(round(pr,2)), (20, 370), font, font_scale, text_color, font_thickness, lineType=cv2.LINE_AA)\n",
    "    \n",
    "#     return black_frame\n",
    "\n",
    "    \n",
    "\n",
    "    return result_frame, yolo_frame, results, area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c9329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5633c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion(mtion_frame, prvs, new):\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, new, None, \n",
    "                                        0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # Overlay motion visualization onto the original frame\n",
    "    for y in range(0, motion_frame.shape[0], 10):\n",
    "        for x in range(0, motion_frame.shape[1], 10):\n",
    "            fx, fy = flow[y, x]\n",
    "            cv2.line(motion_frame, (x, y), (int(x + fx), int(y + fy)), [0,0,255], 1)\n",
    "\n",
    "    return flow, motion_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a359c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e25750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in capturing frames\n"
     ]
    }
   ],
   "source": [
    "start_frame = 1000  # Change this to the frame number you want to start from\n",
    "\n",
    "cap = cv2.VideoCapture('../demoVideos/paperFire1.mp4')\n",
    "# cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "_, old_frame = cap.read()\n",
    "\n",
    "#### variables for yolo #####\n",
    "yolo_area_frame = np.zeros_like(old_frame)\n",
    "old_area = 0\n",
    "areas = []\n",
    "area_growth = []\n",
    "\n",
    "#### variables for motion #####\n",
    "# -> -> - > Clockwise positive direction\n",
    "motion_frame = np.zeros_like(old_frame)\n",
    "prvs = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "avgx = []\n",
    "avgy = []\n",
    "angles = []\n",
    "speed = []\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, new_frame = cap.read()\n",
    "    \n",
    "    # Break the loop if the video is over\n",
    "    if not ret:\n",
    "        print('Error in capturing frames')\n",
    "        break\n",
    "    \n",
    "    # Convert the frame from OpenCV format (BGR) to PIL format (RGB)\n",
    "    frame_pil = Image.fromarray(cv2.cvtColor(new_frame, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Area analysis using YOLO\n",
    "    yolo_result_frame, yolo_frame, yolo_results, new_area = yolo(frame_pil, yolo_area_frame)\n",
    "    areas.append(new_area)\n",
    "    area_growth.append(new_area-old_area)\n",
    "    old_area = new_area\n",
    "    \n",
    "    cv2.imshow('YOLOv5 result', yolo_result_frame)\n",
    "    \n",
    "\n",
    "    # Motion analysis using Farneback\n",
    "    new = cv2.cvtColor(new_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    flow, motion_frame = motion(motion_frame, prvs, new)\n",
    "    \n",
    "    cv2.imshow('Motion analysis', motion_frame)\n",
    "    \n",
    "    prvs = new\n",
    "    \n",
    "    # Get average flow direction\n",
    "    avgx.append(np.mean(flow[..., 0]))\n",
    "    avgy.append(np.mean(flow[..., 1]))\n",
    "\n",
    "\n",
    "    if len(avgx) > 30: \n",
    "        avg_fx = np.mean(avgx)\n",
    "        avg_fy = np.mean(avgy)\n",
    "        avg_direction_angle = np.arctan2(avg_fy, avg_fx)\n",
    "        avg_direction_degrees = np.degrees(avg_direction_angle)\n",
    "        \n",
    "        avg_speed = np.sqrt(avg_fx**2 + avg_fy**2)\n",
    "        \n",
    "        speed.append(avg_speed)\n",
    "        \n",
    "        angles.append(avg_direction_degrees)\n",
    "\n",
    "        # Set text on black_frame\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(new_frame, f\"Direction wrt X+: {avg_direction_degrees:.2f} degrees\", (10, 30), font, 1, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        avgx.pop()\n",
    "        avgy.pop()\n",
    "        \n",
    "    cv2.imshow('Frame', new_frame)\n",
    "    \n",
    "    # Press q to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d1bf1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d827d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc9d9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get min and max values for each variable\n",
    "min_area = min(areas)\n",
    "max_area = max(areas)\n",
    "min_growth = min(area_growth)\n",
    "max_growth = max(area_growth)\n",
    "min_speed = min(speed)\n",
    "max_speed = max(speed)\n",
    "min_angle = min(angles)\n",
    "max_angle = max(angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf9c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1f0ef7f",
   "metadata": {},
   "source": [
    "### Code to plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ee8a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# area_scaler = MinMaxScaler()\n",
    "# areas_normalized = area_scaler.fit_transform(np.array(areas).reshape(-1, 1)).flatten()\n",
    "\n",
    "# growth_scaler = MinMaxScaler()\n",
    "# area_growth_normalized = growth_scaler.fit_transform(np.array(area_growth).reshape(-1, 1)).flatten()\n",
    "\n",
    "# speed_scaler = MinMaxScaler()\n",
    "# speed_normalized = speed_scaler.fit_transform(np.array(speed).reshape(-1, 1)).flatten()\n",
    "\n",
    "cap = cv2.VideoCapture('../demoVideos/paperFire1.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Generate the x-axis values in seconds\n",
    "frame_numbers = np.arange(len(areas))  # Assuming areas, area_growth, speed all have the same length\n",
    "time_seconds = frame_numbers / fps\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "\n",
    "# Plot for areas\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.lineplot(x=time_seconds, y=areas, color='b', linewidth=1)\n",
    "plt.ylabel('Area (pixels)', fontsize=12)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.title(f'Area (Min: {min(areas):.2f}, Max: {max(areas):.2f}, Dev: {np.std(areas):.2f})')\n",
    "\n",
    "# Plot for area growth\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.lineplot(x=time_seconds, y=area_growth, color='r', linewidth=1)\n",
    "plt.ylabel('Growth (pixels)', fontsize=12)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.title(f'Growth (Min: {min(area_growth):.2f}, Max: {max(area_growth):.2f}, Dev: {np.std(area_growth):.2f})')\n",
    "\n",
    "# Plot for speed\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.lineplot(x=time_seconds[:632], y=speed, color='g', linewidth=1)\n",
    "plt.ylabel('Speed (pixels)', fontsize=12)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.title(f'Speed (Min: {min(speed):.2f}, Max: {max(speed):.2f}, Dev: {np.std(speed):.2f})')\n",
    "\n",
    "# Plotting polar plot in the second column\n",
    "plt.subplot(2, 2, 4, polar=True)\n",
    "plt.hist(np.radians(angles), bins=30, color='skyblue', alpha=0.7)\n",
    "plt.xlabel('Direction', fontsize=12)\n",
    "plt.gca().set_theta_direction(-1)\n",
    "plt.gca().set_rticks([])\n",
    "plt.title('Direction')\n",
    "\n",
    "# Optionally, adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "plt.savefig('fire_metrics.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9f0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f31f19d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0dbf30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7ad399d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "632"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8118f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5d6cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envfire",
   "language": "python",
   "name": "envfire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
